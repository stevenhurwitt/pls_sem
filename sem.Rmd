---
title: "Structural Equation Modeling (SEM)"
author: "Steven Hurwitt"
date: "4/14/2020"
output:
  pdf_document: default
  html_document: default
header-includes: \usepackage{amsmath}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Latent Growth Model
We start with the latent growth model given as:

$$\begin{bmatrix} y_{0i} \\ y_{1i} \\ y_{2i} \\ y_{3i} \end{bmatrix} = \Lambda \begin{bmatrix} \eta_{1i} \\ \eta_{2i} \end{bmatrix} + \begin{bmatrix} e_{0i} \\ e_{1i} \\ e_{2i} \\ e_{3i} \end{bmatrix}$$
From (Lai, 2020) we know $\eta_{1i}$ is the intercept for person $i$ and $\eta_{2i}$ is the slope. $e_{01}, ..., e_{3i}$ are the within-person level error terms. These are all normally distributed as follows:

$$\begin{bmatrix} \eta_{1i} \\ \eta_{2i} \end{bmatrix} \sim \mathcal{N} \bigg( \begin{bmatrix} \alpha_{1} \\ \alpha_{2} \end{bmatrix},\begin{bmatrix} \phi_{11} \ \phi_{21} \\ \phi_{21} \ \phi_{22} \end{bmatrix} \bigg) $$
$$\begin{bmatrix} e_{0i} \\ e_{1i} \\ e_{2i} \\ e_{3i} \end{bmatrix} \sim \mathcal{N} \Bigg( \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix} \theta_{11} \ 0 \ 0 \ 0 \\ 0 \ \theta_{22} \ 0 \ 0 \\ 0 \ 0 \ \theta_{33} \ 0 \\ 0 \ 0 \ 0 \ \theta_{44} \end{bmatrix} \Bigg)$$
These variables will later be generated in R.

## Specifying the Model
We start by including the packages,

```{r, results='hide', message=FALSE,warning=FALSE}
library(lavaan)
library(semPlot)
library(mnormt)
```

and specifiying the latent growth model.
```{r}
growth_model <- "i =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
                 s =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
                 i ~~ 1 * i
                 s ~~ 0.2 * s + 0.1 * i
                 y1 ~~ 0.5 * y1
                 y2 ~~ 0.5 * y2
                 y3 ~~ 0.5 * y3
                 y4 ~~ 0.5 * y4
                 i ~ 1 * 1
                 s ~ 0.5 * 1"

semPaths(semPlotModel_lavaanModel(growth_model))
```


Let's break this down. 

### Latent Variables
The first two lines specify the latent variables (intercept and slope) in terms of the observed variables. The symbol =~ is read as "is measured by". These coefficients represent the factor loadings, or the $\Lambda$ matrix above.
```{r, results='hide'}
"i =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
 s =~ 0*y1 + 1*y2 + 2*y3 + 3*y4"
```

### Variance/Covariances
The following lines represent variances and covariances. The intercept and slope coefficients make up the matrix $\phi$ above, while the coefficients on the observed variables make up the matrix $\theta$. The symbol ~~ is read as "is correlated with".
```{r, results='hide'}
"i ~~ 1 * i
 s ~~ 0.2 * s + 0.1 * i
 y1 ~~ 0.5 * y1
 y2 ~~ 0.5 * y2
 y3 ~~ 0.5 * y3
 y4 ~~ 0.5 * y4"
```

### Intercepts
The last lines represent the intercepts, which correspond to the $\alpha$ vector. The ~ symbol is simply read as "intercept".
```{r, results='hide'}
"i ~ 1*1
 s ~ .5*1"
```

## Generating the Data
Lai gives the following code to generate the data:
```{r, results='hide'}
set.seed(123)

N <- 100 # sample size

# Define the Fixed Parameters
alpha <- c(1, 0.5)  # latent means
Phi <- matrix(c(1, 0.1, 
                0.1, 0.2), nrow = 2)  # latent variances/covariances
Lambda <- cbind(c(1, 1, 1, 1), 
                c(0, 1, 2, 3))  # factor loadings
Theta <- diag(0.5, nrow = 4)
# Generate latent factor scores
eta <- rmnorm(N, mean = alpha, varcov = Phi)
# Generate residuals:
e <- rmnorm(N, varcov = Theta)
# Compute outcome scores: y_i = t(Lambda %*% eta_i) + e
y <- tcrossprod(eta, Lambda) + e
# Make it a data frame
colnames(y) <- paste0("y", 1:4)
df <- as.data.frame(y)
```

### Analyzing the Data w/ lavaan
The data can be analyzed the lavaan package as follows:
```{r}
# True model
m1 <- 'i =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
       s =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
       i ~~ s'
# Model without random slopes
m2 <- 'i =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
       s =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
       s ~~ 0*i + 0*s'
m1_fit <- growth(m1, data = df)
m2_fit <- growth(m2, data = df)
```

Both of the model fit objects have a variety of fit measures that can be returned. These include fit indices, chi-square values, degrees of freedom, p-values, parameter estimates and a covariance matrix.

### Bootstrapping
We can also bootstrap to get standard errors of different fit measures.
```{r, results = 'hide'}
bootstrapLavaan(m1_fit, R = 1000L, type = "bollen.stine",
                FUN = fitMeasures, fit.measures = c("cfi"))
```

Lai then goes on to a full simulation study examining different sample sizes, means of slopes and variances of slopes. We pause here to try and relate this to PLS-PM methods.

## PLS-PM SEM
Moving to a PLS framework, it is useful to understand how PLS-PM models are defined.These include a measurement model, which describes the relationships between constructs and observed indicators, as well as a structural model, which gives the relationships between constructs.

There are also factor or composite models (which I believe relate to the constructs). There is different terminologies for these, so I am unsure if they are the same as reflexive and formative models, which relate the types of weights used in the constructs (either correlation or regression weights). Factor models are variables of sets of indicators that can be explained by a common factor and independent randomm error. Composite models are linear combinations of respective indicators. There is no restriction on covariance between indicators.

Let's break down an example used in the seminr documentation.

### PLS SEM in R
Start by importing required packages and loading the dataset "mobi".
```{r, results='hide', message=FALSE,warning=FALSE}
library(seminr)
library(ggplot2)
library(reshape)

mobi = mobi
```

### Measurement Model

We make the measurement model out of composites or reflectives, along with interaction terms. These consist of single or multi-items (variables) along with the weights (mode A are correlation weights, mode B are regression weights).
```{r}
mobi_mm <- constructs(
  composite("Image",         multi_items("IMAG", 1:5), weights = mode_B),
  composite("Expectation",   multi_items("CUEX", 1:3), weights = regression_weights),
  composite("Quality",       multi_items("PERQ", 1:7), weights = mode_A),
  composite("Value",         multi_items("PERV", 1:2), weights = correlation_weights),
  reflective("Satisfaction", multi_items("CUSA", 1:3)),
  reflective("Complaints",   single_item("CUSCO")),
  higher_composite("HOC", c("Value", "Satisfaction"), orthogonal, mode_A),
  interaction_term(iv = "Image", moderator = "Expectation", method =  orthogonal, weights = mode_A),
  reflective("Loyalty",      multi_items("CUSL", 1:3))
)
```

### Structural Model

The structural model defines the relationships between variables in the path network. These include a 'from' and 'to' statement.
```{r}
mobi_sm <- relationships(
  paths(from = "Image",        to = c("Expectation", "Satisfaction", "Loyalty")),
  paths(from = "Expectation",  to = c("Quality", "Value", "Satisfaction")),
  paths(from = "Quality",      to = c("Value", "Satisfaction")),
  paths(from = "Value",        to = c("Satisfaction")),
  paths(from = "Satisfaction", to = c("Complaints", "Loyalty")),
  paths(from = "Complaints",   to = "Loyalty")
)
```

### Model Estimation

Finally we estimate the model using the data, measurement model, structural model and weights. We can look at the summary of the fit, much like a regression model.
```{r}
mobi_pls <- estimate_pls(data = mobi,
                         measurement_model = mobi_mm,
                         structural_model = mobi_sm,
                         inner_weights = path_weighting)

summary(mobi_pls)
```

### Bootstrapping

We again use bootstraping to get standard errors of different measures of fits.
```{r, results = 'hide'}
boot_mobi_pls <- bootstrap_model(seminr_model = mobi_pls,
                                 nboot = 1000,
                                 cores = 2)

summary(boot_mobi_pls)
```

## Questions

This brings me to a few different questions about fitting the latent growth model in lavaan vs. seminr. 

1. How do we represent the factor loadings in PLS methodology? Do we need to use the latent model described in lavaan and explicitly calculate values for the intercept and slope per observation? i.e. make i and s explicit variables in R and calculate them using the latent formulas?

2. For the measurement model, what weights do we want to use, correlation or regression?

3. For the structural model, how do we represent the latent slope and intercept?

4. What happens to the variance/covariance specifications in lavaan when going to seminr? How do we translate these into a structural model?

5. Is it worth it to try converting examples in seminr to the plspm package and vice-versa? Looked into some examples in plspm and the model specifications are a little different (but similar). Might have more informative plots.

6. Emailed Lai about latent growth model and translating it to PLS.